{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikiracing Agent\n",
    "\n",
    "Wikiracing is a game in which players compete to navigate from one Wikipedia page to another using only internal link. [Full description here](https://en.wikipedia.org/wiki/Wikiracing).\n",
    "\n",
    "The code below demonstrates how we can easily:\n",
    "1. Build a fully-functioning agent using Large Language Models.\n",
    "1. Validate the AI-generated results using plain Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ready, Set, Go!\n",
    "#### Library imports and environment initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import cache\n",
    "from typing import Union\n",
    "\n",
    "import nest_asyncio\n",
    "import wikipedia\n",
    "from dotenv import load_dotenv\n",
    "from networkx import DiGraph, is_simple_path\n",
    "from openai import AsyncAzureOpenAI\n",
    "from pydantic import BaseModel\n",
    "from pydantic_ai import Agent, ModelRetry, Tool\n",
    "from pydantic_ai.models.openai import OpenAIModel\n",
    "from pydantic_ai.usage import UsageLimits\n",
    "from rich import print\n",
    "\n",
    "# Workaround for runnning Pydantic AI in notebooks\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Load model configuration and api key from environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the Agent's interface to query Wikipedia - i.e. the \"Tool\" that we will provide to the LLM to call.\n",
    "As an aside the term \"call\" is a misnomer: The LLM is merely responding to a prompt and has no ability to directly \"call\" anything. What happens underneath the hood is that there's a Pythonic framework (in our case Pydantic AI) that takes a structured response from the LLM asking for the tool to be called (with arguments), then calls the tool with the arguments and calls the LLM again with the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cache\n",
    "def get_outbound_links(page_name: str) -> list[str]:\n",
    "    print(f'Getting outbound links for: \"{page_name}\"')\n",
    "\n",
    "    try:\n",
    "        page = wikipedia.WikipediaPage(page_name, redirect=True)\n",
    "        return page.links\n",
    "    except wikipedia.exceptions.PageError as e:\n",
    "        raise ModelRetry(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pulling it all together into an Agent definition\n",
    "Note the structured result models, these will be useful for later integration with Python validation code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PathFound(BaseModel):\n",
    "    pages_by_title: list[str]\n",
    "\n",
    "\n",
    "class NoPathFound(BaseModel):\n",
    "    pass\n",
    "\n",
    "ResultType = Union[PathFound, NoPathFound]\n",
    "\n",
    "\n",
    "# Agent itself, note the typing of the \n",
    "WikiracingAgent = Agent[None, ResultType](\n",
    "    model=OpenAIModel(\n",
    "        model_name=\"gpt-4o\",\n",
    "        openai_client=AsyncAzureOpenAI(),\n",
    "    ),\n",
    "    result_type=ResultType,  # type: ignore https://ai.pydantic.dev/results/#structured-result-validation\n",
    "    result_retries=3,\n",
    "    system_prompt=\"You are a Wikipedia agent that can get outbound links from a page.\",\n",
    "    tools=[Tool(function=get_outbound_links)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation Function\n",
    "We can't *prevent* the LLM from emitting an invalid result, but we can absolutely validate the actual result via Python code (read: that we tested and decided to trust) before returning the answer to our consumers. \n",
    "\n",
    "In this example we're going to dip into [Graph Theory](https://en.wikipedia.org/wiki/Graph_theory) by populating a graph with the pages as nodes and links as edges, then check if the path is valid using [NetworkX](https://networkx.org/) (another excellent library).\n",
    "\n",
    "Note that we're not immediately failing the Agent's run if the result is invalid, but instead are raising the special `ModelRetry` exception, as a signal for the agent to incorporate into the run and try to bring the chain of thought back on track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@WikiracingAgent.result_validator\n",
    "def validate_path(data: ResultType) -> ResultType:\n",
    "    # Validate the identified solution\n",
    "    if isinstance(data, PathFound):\n",
    "        # Instantiate a graph\n",
    "        g = DiGraph()\n",
    "\n",
    "        # For every page in the identified solution, add all outbound links\n",
    "        for current_page_title in data.pages_by_title:\n",
    "            [\n",
    "                g.add_edge(current_page_title, linked_title)\n",
    "                for linked_title in get_outbound_links(current_page_title)\n",
    "            ]\n",
    "\n",
    "        if not is_simple_path(g, data.pages_by_title):\n",
    "            raise ModelRetry(\"Path is not valid\")\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top-level Python Abstraction\n",
    "Note the strongly typed arguments and return value, with differentiation between success and failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def race(start: str, end: str) -> ResultType:\n",
    "    return WikiracingAgent.run_sync(\n",
    "        f\"Find a path of pages from '{start}' to '{end}'\",\n",
    "         # Limit the total number of tokens used by the agent to prevent runaway costs\n",
    "        usage_limits=UsageLimits(total_tokens_limit=250000),\n",
    "    ).data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Getting outbound links for: <span style=\"color: #008000; text-decoration-color: #008000\">\"Lindsay Lohan\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Getting outbound links for: \u001b[32m\"Lindsay Lohan\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Getting outbound links for: <span style=\"color: #008000; text-decoration-color: #008000\">\"Condoleezza Rice\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Getting outbound links for: \u001b[32m\"Condoleezza Rice\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Getting outbound links for: <span style=\"color: #008000; text-decoration-color: #008000\">\"George Clooney\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Getting outbound links for: \u001b[32m\"George Clooney\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Getting outbound links for: <span style=\"color: #008000; text-decoration-color: #008000\">\"MTV\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Getting outbound links for: \u001b[32m\"MTV\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Getting outbound links for: <span style=\"color: #008000; text-decoration-color: #008000\">\"New York City\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Getting outbound links for: \u001b[32m\"New York City\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Getting outbound links for: <span style=\"color: #008000; text-decoration-color: #008000\">\"Donald Trump\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Getting outbound links for: \u001b[32m\"Donald Trump\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Getting outbound links for: <span style=\"color: #008000; text-decoration-color: #008000\">\"Barack Obama\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Getting outbound links for: \u001b[32m\"Barack Obama\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Getting outbound links for: <span style=\"color: #008000; text-decoration-color: #008000\">\"Lindsay Lohan\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Getting outbound links for: \u001b[32m\"Lindsay Lohan\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Getting outbound links for: <span style=\"color: #008000; text-decoration-color: #008000\">\"Donald Trump\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Getting outbound links for: \u001b[32m\"Donald Trump\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Getting outbound links for: <span style=\"color: #008000; text-decoration-color: #008000\">\"Barack Obama\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Getting outbound links for: \u001b[32m\"Barack Obama\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PathFound</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">pages_by_title</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Lindsay Lohan'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Donald Trump'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Barack Obama'</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mPathFound\u001b[0m\u001b[1m(\u001b[0m\u001b[33mpages_by_title\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'Lindsay Lohan'\u001b[0m, \u001b[32m'Donald Trump'\u001b[0m, \u001b[32m'Barack Obama'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = race(\"Lindsay Lohan\", \"Barack Obama\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The result: We have a winner!\n",
    "\n",
    "Note that in this case the LLM meandered a lot, querying pages out of order (which isn't necessarily wrong, as we haven't prescribed a linear exploration strategy), and the overhead of couple of pages twice (incurring cost and latency).\n",
    "\n",
    "That said: The agent got to the right answer and with a strong guarantee of correctness via the validation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parting Thoughts\n",
    "1. Isn't this exciting?\n",
    "1. Note the strategy of shifting trust, insofar correctness, from the LLM to Python code. I'll take the task of writing 10 lines of Python to validate a structured response over the alternative ofsetting up linguistic LLM guardrails (more on those in a separate post) any day.\n",
    "1. There's room for cutting down cost and latency with tighter prompting of exploration strategy, but that's a topic for another post.\n",
    "1. Another open question is how will other LLM models benchmark against each other? \n",
    "\n",
    "Stay tuned!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
